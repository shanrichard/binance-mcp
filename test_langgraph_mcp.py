#!/usr/bin/env python3
"""
LangGraph + Binance MCP é›†æˆæµ‹è¯•è„šæœ¬

æµ‹è¯•MCP Adapteræ˜¯å¦æ­£ç¡®å°†Binance MCPå·¥å…·é›†æˆåˆ°LangGraphä¸­
"""

import asyncio
import os
import sys
from typing import Annotated, Sequence, TypedDict

try:
    from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
    from langchain_openai import ChatOpenAI
    from langgraph import StateGraph, END
    # è¿™é‡Œéœ€è¦æ‰¾åˆ°æ­£ç¡®çš„MCPé€‚é…å™¨åŒ…
    # from mcp_langchain import MCPToolkit  # å¯èƒ½çš„åŒ…å
    from langchain_community.adapters.mcp import MCPToolkit  # æˆ–è€…è¿™ä¸ª
except ImportError as e:
    print(f"âŒ ä¾èµ–åŒ…å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·å®‰è£…å¿…è¦çš„åŒ…:")
    print("  pip install langgraph langchain-openai langchain-community")
    print("  pip install mcp-langchain  # æˆ–æ­£ç¡®çš„MCPé€‚é…å™¨åŒ…å")
    sys.exit(1)

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], "The messages in the conversation"]

async def test_mcp_toolkit():
    """æµ‹è¯•MCP ToolkitåŸºæœ¬åŠŸèƒ½"""
    print("ğŸ”§ æµ‹è¯•MCP ToolkitåŸºæœ¬åŠŸèƒ½...")
    
    try:
        # å°è¯•è¿æ¥åˆ°MCPæœåŠ¡å™¨
        mcp_toolkit = MCPToolkit(
            server_command="python",
            server_args=["-m", "binance_mcp.simple_server"],
            server_env={}
        )
        
        # è·å–å·¥å…·åˆ—è¡¨
        tools = mcp_toolkit.get_tools()
        print(f"âœ… æˆåŠŸåŠ è½½ {len(tools)} ä¸ªMCPå·¥å…·:")
        for tool in tools:
            print(f"  - {tool.name}: {tool.description}")
        
        return tools
        
    except Exception as e:
        print(f"âŒ MCP Toolkitè¿æ¥å¤±è´¥: {e}")
        return None

async def test_direct_tool_call(tools):
    """æµ‹è¯•ç›´æ¥å·¥å…·è°ƒç”¨"""
    print("\nğŸ”§ æµ‹è¯•ç›´æ¥å·¥å…·è°ƒç”¨...")
    
    try:
        # æ‰¾åˆ°get_server_infoå·¥å…·
        server_info_tool = None
        for tool in tools:
            if tool.name == "get_server_info":
                server_info_tool = tool
                break
        
        if not server_info_tool:
            print("âŒ æœªæ‰¾åˆ°get_server_infoå·¥å…·")
            return False
            
        # è°ƒç”¨å·¥å…·
        result = server_info_tool.invoke({})
        print(f"âœ… æœåŠ¡å™¨ä¿¡æ¯: {result}")
        
        # æµ‹è¯•get_tickerå·¥å…·
        ticker_tool = None
        for tool in tools:
            if tool.name == "get_ticker":
                ticker_tool = tool
                break
        
        if ticker_tool:
            print("\nğŸ”§ æµ‹è¯•ä»·æ ¼æŸ¥è¯¢å·¥å…·...")
            ticker_result = ticker_tool.invoke({"symbol": "BTC/USDT"})
            print(f"âœ… BTCä»·æ ¼: {ticker_result}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
        return False

async def test_langgraph_integration(tools):
    """æµ‹è¯•LangGraphé›†æˆ"""
    print("\nğŸ”§ æµ‹è¯•LangGraphé›†æˆ...")
    
    # æ£€æŸ¥OpenAI APIå¯†é’¥
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("âš ï¸  æœªè®¾ç½®OPENAI_API_KEYï¼Œè·³è¿‡LangGraphæµ‹è¯•")
        return False
    
    try:
        # åˆå§‹åŒ–LLM
        llm = ChatOpenAI(
            api_key=openai_api_key,
            model="gpt-4",
            temperature=0
        )
        
        # å°†å·¥å…·ç»‘å®šåˆ°LLM
        llm_with_tools = llm.bind_tools(tools)
        
        def call_model(state: AgentState):
            """è°ƒç”¨LLMå¤„ç†æ¶ˆæ¯"""
            messages = state["messages"]
            response = llm_with_tools.invoke(messages)
            return {"messages": [response]}
        
        def call_tools(state: AgentState):
            """è°ƒç”¨å·¥å…·"""
            messages = state["messages"]
            last_message = messages[-1]
            
            tool_outputs = []
            for tool_call in last_message.tool_calls:
                # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
                tool = next(t for t in tools if t.name == tool_call["name"])
                
                try:
                    result = tool.invoke(tool_call["args"])
                    tool_outputs.append(ToolMessage(
                        content=str(result),
                        tool_call_id=tool_call["id"]
                    ))
                except Exception as e:
                    tool_outputs.append(ToolMessage(
                        content=f"å·¥å…·è°ƒç”¨å¤±è´¥: {e}",
                        tool_call_id=tool_call["id"]
                    ))
            
            return {"messages": tool_outputs}
        
        def should_continue(state: AgentState):
            """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­"""
            messages = state["messages"]
            last_message = messages[-1]
            
            if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                return "tools"
            return END
        
        # æ„å»ºå·¥ä½œæµå›¾
        workflow = StateGraph(AgentState)
        workflow.add_node("agent", call_model)
        workflow.add_node("tools", call_tools)
        workflow.set_entry_point("agent")
        
        workflow.add_conditional_edges(
            "agent",
            should_continue,
            {
                "tools": "tools",
                END: END
            }
        )
        workflow.add_edge("tools", "agent")
        
        app = workflow.compile()
        
        # æµ‹è¯•å¯¹è¯
        test_input = {
            "messages": [HumanMessage(content="è¯·è·å–æœåŠ¡å™¨ä¿¡æ¯")]
        }
        
        result = await app.ainvoke(test_input)
        final_message = result["messages"][-1]
        print(f"âœ… LangGraphå“åº”: {final_message.content}")
        
        return True
        
    except Exception as e:
        print(f"âŒ LangGraphé›†æˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹Binance MCP + LangGraphé›†æˆæµ‹è¯•\n")
    
    # 1. æµ‹è¯•MCPæœåŠ¡å™¨è¿æ¥
    print("ğŸ“¡ æ£€æŸ¥Binance MCPæœåŠ¡å™¨çŠ¶æ€...")
    import subprocess
    try:
        result = subprocess.run(
            ["binance-mcp", "status"], 
            capture_output=True, 
            text=True,
            timeout=10
        )
        if result.returncode == 0:
            print("âœ… MCPæœåŠ¡å™¨è¿è¡Œä¸­")
        else:
            print(f"âš ï¸  MCPæœåŠ¡å™¨çŠ¶æ€å¼‚å¸¸: {result.stderr}")
            print("è¯·è¿è¡Œ: binance-mcp start -d")
    except subprocess.TimeoutExpired:
        print("âš ï¸  MCPæœåŠ¡å™¨çŠ¶æ€æ£€æŸ¥è¶…æ—¶")
    except FileNotFoundError:
        print("âŒ binance-mcpå‘½ä»¤æœªæ‰¾åˆ°ï¼Œè¯·ç¡®è®¤å·²å®‰è£…")
        return
    
    # 2. æµ‹è¯•MCP Toolkit
    tools = await test_mcp_toolkit()
    if not tools:
        print("\nâŒ MCP Toolkitæµ‹è¯•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return
    
    # 3. æµ‹è¯•ç›´æ¥å·¥å…·è°ƒç”¨
    tool_success = await test_direct_tool_call(tools)
    if not tool_success:
        print("\nâŒ å·¥å…·è°ƒç”¨æµ‹è¯•å¤±è´¥")
        return
    
    # 4. æµ‹è¯•LangGraphé›†æˆ
    langgraph_success = await test_langgraph_integration(tools)
    
    # æ€»ç»“
    print("\n" + "="*50)
    print("ğŸ¯ æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"  - MCPè¿æ¥: {'âœ…' if tools else 'âŒ'}")
    print(f"  - å·¥å…·è°ƒç”¨: {'âœ…' if tool_success else 'âŒ'}")
    print(f"  - LangGraphé›†æˆ: {'âœ…' if langgraph_success else 'âŒ'}")
    
    if tools and tool_success and langgraph_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼LangGraph + Binance MCP é›†æˆæˆåŠŸï¼")
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³é…ç½®")

if __name__ == "__main__":
    asyncio.run(main())